{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = './data'\n",
    "PGN = os.path.join(DATA_ROOT, 'data.pgn')\n",
    "STOCKFISH = os.path.join(DATA_ROOT, 'stockfish.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get to know the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's take a look at the PGN file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PGN) as f:\n",
    "    for i in range(100):\n",
    "        print(next(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very well structured text data. We need a function to parse it into a DataFrame for easier processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pgn2dataframe(file_obj):\n",
    "    \"\"\"Read a PGN file and return a `pandas.DataFrame` containing all data.\"\"\"\n",
    "    \n",
    "    # Store all match data as a list of dictionary\n",
    "    json_objs = []\n",
    "    entry = {}\n",
    "    # Since move sequences span multiple lines, we should\n",
    "    # store all lines and join them at appropriate time\n",
    "    move_seq = []\n",
    "    # Regex pattern for metadata lines\n",
    "    pattern = re.compile(r'\\[([A-Za-z]+) \"(.*)\"\\]')\n",
    "    \n",
    "    # Loop through each line in the file, building the list of match data\n",
    "    for row in file_obj:\n",
    "        row_ = row.strip()\n",
    "        m = pattern.match(row_)\n",
    "        if m:\n",
    "            # Metadata line\n",
    "            entry[m.group(1)] = m.group(2)\n",
    "        else:\n",
    "            if not row_:\n",
    "                # Empty line: skip\n",
    "                continue\n",
    "            for result in '0-1', '1-0', '1/2-1/2':\n",
    "                if row_.endswith(result):\n",
    "                    # Last row of move sequence.\n",
    "                    # Remove the result at the end\n",
    "                    t = row_[:-len(result)].strip()\n",
    "                    if t:\n",
    "                        move_seq.append(t)\n",
    "                    entry['Moves'] = ' '.join(move_seq)\n",
    "                    # Here we already have a complete record of 1 match\n",
    "                    # Put the record to our list then reset the temporary\n",
    "                    # object to record the next match\n",
    "                    json_objs.append(entry)\n",
    "                    entry = {}\n",
    "                    move_seq = []\n",
    "                    break\n",
    "            else:\n",
    "                    # Move sequence line\n",
    "                    move_seq.append(row_)\n",
    "\n",
    "    return pd.DataFrame(json_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse pgn data to json\n",
    "# Might take a few seconds\n",
    "with open(PGN) as f:\n",
    "    all_matches = pgn2dataframe(f)\n",
    "\n",
    "all_matches.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good.\n",
    "The only columns with null are `\"BlackElo\"` and `\"WhiteElo\"`, which are the ones we have to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can drop those `\"??\"` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in 'Black', 'Date', 'Round', 'Site', 'White':\n",
    "    print(all_matches[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we don't need those columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_matches.drop(columns=['Black', 'Date', 'Round', 'Site', 'White'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `\"Event\"` column as index column. Will come in handy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['Event'] = all_matches['Event'].astype(np.int64)\n",
    "all_matches.set_index('Event', inplace=True)\n",
    "all_matches.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for the Stockfish file\n",
    "\n",
    "It's already in CSV format. Convenient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_scores = pd.read_csv(STOCKFISH)\n",
    "move_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join the 2 data frames into 1 here.\n",
    "Note that it won't work if we don't set `\"Event\"` to be the index column in both data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = all_matches.join(move_scores.set_index('Event'))\n",
    "all_matches.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't need `move_scores` anymore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del move_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_matches['WhiteElo'] = pd.to_numeric(all_matches['WhiteElo'])\n",
    "all_matches['BlackElo'] = pd.to_numeric(all_matches['BlackElo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineer & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@todo: I choose not to make use of the `\"Moves\"` column and remove it completely.\n",
    "You can try to make use of it, for example by look up the first few moves to know the name of the opening pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_matches.drop('Moves', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a new column `\"WhitePoint\"` to replace `\"Result\"`.\n",
    "We don't need black point since we know that `black point + white point = 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@todo: It might be better to treat `\"Result\"` as categorical data as there are only 3 possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['WhitePoint'] = all_matches['Result'].apply(lambda x: eval(x[:len(x)//2]))\n",
    "all_matches.drop(columns=['Result'], inplace=True)\n",
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['WhitePoint'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White wins 38.6% to Black's 30.3%. Let's look at the distribution of black and white's elo rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15,8))\n",
    "all_matches[all_matches['WhiteElo'].notnull()]['WhiteElo'].plot.hist(ax=axes[0], bins=20, title='WhiteElo')\n",
    "all_matches[all_matches['BlackElo'].notnull()]['BlackElo'].plot.hist(ax=axes[1], bins=20, title='BlackElo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is unbalanced toward high levels players (rating over 2000).\n",
    "This might cause some overfitting later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the `\"MoveScores\"` column from strings to list of strings, and look at the length of the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_matches['MoveScores'] = all_matches['MoveScores'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "all_matches['MatchLength'] = all_matches['MoveScores'].apply(len)\n",
    "all_matches['MatchLength'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['MatchLength'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most games last 60-100 moves, with some extreme cases.\n",
    "There is no way we can predict the rating of a player with just one or 2 moves,\n",
    "so we can consider too-short games anomalies and handle them accordingly.\n",
    "\n",
    "@todo: Here I choose to remove them completely from the training set.\n",
    "You might try a different strategy to handle short games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All short games (< 8 moves)\n",
    "short_games = all_matches[all_matches['MatchLength'] < 8]\n",
    "len(short_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all short games\n",
    "all_matches.drop(short_games.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to analyze the flow of the game. Here I choose to simply count the good/bad moves each player made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_move_scores(\n",
    "    move_scores,\n",
    "    *,\n",
    "    excellent_thres=300,\n",
    "    good_thres=100,\n",
    "    mistake_thres=-100,\n",
    "    blunder_thres=-300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Count the number of each player's moves in different categories.\n",
    "    \n",
    "    The categories are:\n",
    "    - Excellent: Moves that give major advantage to the player\n",
    "    - Good: Moves that give minor advantage to the player\n",
    "    - Mistake: Moves that give minor advantage to the opponent\n",
    "    - Blunder: Moves that give major advantage to the opponent\n",
    "    \n",
    "    We don't need to consider the moves that don't fall in the above categories,\n",
    "    because it correlates heavily with those.\n",
    "    \n",
    "    @todo:\n",
    "        Currently the threshold values are just some random numbers.\n",
    "        They can be changed to some better values, or use an adaptive strategy\n",
    "        to better classify them.\n",
    "    \"\"\"\n",
    "    white = {'excellent': 0, 'good': 0, 'mistake': 0, 'blunder': 0}\n",
    "    black = {'excellent': 0, 'good': 0, 'mistake': 0, 'blunder': 0}\n",
    "    last_score = 0\n",
    "    \n",
    "    # Coefficient: white = 1, black = -1\n",
    "    coef = 1\n",
    "    for i, score_str in enumerate(move_scores):\n",
    "        current_player = black if i % 2 == 1 else white\n",
    "        try:\n",
    "            score = int(score_str)\n",
    "        except:\n",
    "            score = last_score\n",
    "        change = score - last_score\n",
    "        point = coef * change\n",
    "        if point >= excellent_thres:\n",
    "            current_player['excellent'] += 1\n",
    "        elif point >= good_thres:\n",
    "            current_player['good'] += 1\n",
    "        elif point <= blunder_thres:\n",
    "            current_player['blunder'] += 1\n",
    "        elif point <= mistake_thres:\n",
    "            current_player['mistake'] += 1\n",
    "        coef *= -1\n",
    "        last_score = score\n",
    "    \n",
    "    white_move_count = (len(move_scores) + 1) // 2\n",
    "    black_move_count = len(move_scores) // 2\n",
    "    white_ratio = np.array(list(white.values())) / white_move_count\n",
    "    black_ratio = np.array(list(black.values())) / black_move_count\n",
    "    return np.concatenate([black_ratio, white_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    all_matches['black_excellent'],\n",
    "    all_matches['black_good'],\n",
    "    all_matches['black_mistake'],\n",
    "    all_matches['black_blunder'],\n",
    "    all_matches['white_excellent'],\n",
    "    all_matches['white_good'],\n",
    "    all_matches['white_mistake'],\n",
    "    all_matches['white_blunder'],\n",
    ") = zip(*all_matches['MoveScores'].apply(analyze_move_scores))\n",
    "\n",
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have no more use for `\"MoveScores\"`, so let's delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_matches.drop('MoveScores', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "train_data = all_matches[all_matches['WhiteElo'].notnull()]\n",
    "test_data = all_matches[all_matches['WhiteElo'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = train_data.corr()\n",
    "plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\"WhitePoint\"` correlates strongly with many other features.\n",
    "We can remove it, but I choose to leave it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, x_train, y_train, n_folds=5):\n",
    "    kf = KFold(n_folds, shuffle=True).get_n_splits(x_train.values)\n",
    "    score = -cross_val_score(model, x_train.values, y_train.values, scoring='neg_mean_absolute_error', cv=kf)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_data.drop(['BlackElo', 'WhiteElo'], axis=1)\n",
    "y_train = train_data[['BlackElo', 'WhiteElo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = train_and_evaluate(ridge, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyData",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
